# download_models.py - H100 ì—°êµ¬ìš© í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
import os
import time
import json
from datetime import datetime
import argparse
from huggingface_hub import snapshot_download
import shutil

# H100 ì—°êµ¬ì— í•„ìˆ˜ì ì¸ ëª¨ë¸ë“¤
ESSENTIAL_MODELS = {
    # 1. M3 ì„±ëŠ¥ ì—­ì „ í˜„ìƒ ê²€ì¦ìš© (í¬ê¸°ë³„ ë¹„êµ)
    "size_comparison": {
        "models": [
            ("microsoft/DialoGPT-small", "117M", "M3 ì‹¤í—˜ ê¸°ì¤€ì "),
            ("Qwen/Qwen2-1.5B-Instruct", "1.5B", "M3 1.3B ëŒ€ì²´"),
            ("microsoft/Phi-3.5-mini-instruct", "3.8B", "M3 3.8B ì§ì ‘ ë¹„êµ"),
            ("Qwen/Qwen2-7B-Instruct", "7B", "ì¤‘ê°„ í¬ê¸° ê¸°ì¤€"),
            ("microsoft/Phi-3-small-8k-instruct", "7B", "ëŒ€ì•ˆ 7B ëª¨ë¸"),
            ("mistralai/Mistral-7B-Instruct-v0.3", "7B", "Mistral 7B"),
        ],
        "priority": 1,
        "description": "M3 ì„±ëŠ¥ ì—­ì „ í˜„ìƒì„ H100ì—ì„œ ê²€ì¦í•˜ê¸° ìœ„í•œ í¬ê¸°ë³„ ëª¨ë¸"
    },
    
    # 2. ìµœì‹  ì¶”ë¡  íŠ¹í™” ëª¨ë¸ë“¤
    "reasoning_models": {
        "models": [
            ("deepseek-ai/DeepSeek-R1-Distill-Qwen-7B", "7B", "DeepSeek R1 ê²½ëŸ‰í™”"),
            ("deepseek-ai/DeepSeek-R1-Distill-Qwen-14B", "14B", "DeepSeek R1 ì¤‘í˜•"),
            ("deepseek-ai/DeepSeek-R1-Distill-Qwen-32B", "32B", "DeepSeek R1 ëŒ€í˜•"),
            ("Qwen/QwQ-32B-Preview", "32B", "Qwen ì¶”ë¡  íŠ¹í™”"),
            ("Qwen/Qwen2.5-72B-Instruct", "72B", "Qwen ìµœì‹  ëŒ€í˜•"),
        ],
        "priority": 2,
        "description": "2025ë…„ ìµœì‹  ì¶”ë¡  ëŠ¥ë ¥ ê°•í™” ëª¨ë¸ë“¤"
    },
    
    # 3. í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ë“¤
    "korean_models": {
        "models": [
            ("upstage/SOLAR-10.7B-Instruct-v1.0", "10.7B", "ì„¸ê³„ 1ìœ„ í•œêµ­ ëª¨ë¸"),
            ("nlpai-lab/kullm-polyglot-12.8b-v2", "12.8B", "ê³ ë ¤ëŒ€ í•œêµ­ì–´ íŠ¹í™”"),
            ("beomi/llama-2-ko-7b", "7B", "í•œêµ­ì–´ Llama"),
            ("kakaobrain/kogpt", "6B", "ì¹´ì¹´ì˜¤ë¸Œë ˆì¸ ëª¨ë¸"),
        ],
        "priority": 3,
        "description": "í•œêµ­ì–´ ì„±ëŠ¥ ìµœì í™” ëª¨ë¸ë“¤"
    },
    
    # 4. ë²¤ì¹˜ë§ˆí¬ ë¦¬ë” ëª¨ë¸ë“¤
    "benchmark_leaders": {
        "models": [
            ("meta-llama/Llama-3.3-70B-Instruct", "70B", "ìµœì‹  Llama"),
            ("microsoft/Phi-4", "14B", "ìµœì‹  Phi"),
            ("google/gemma-2-27b-it", "27B", "Gemma ëŒ€í˜•"),
            ("mistralai/Mistral-Nemo-Instruct-2407", "12B", "Mistral ìµœì‹ "),
        ],
        "priority": 4,
        "description": "2025ë…„ ë²¤ì¹˜ë§ˆí¬ ë¦¬ë”ë³´ë“œ ìƒìœ„ ëª¨ë¸ë“¤"
    }
}

class H100ModelDownloader:
    def __init__(self, cache_dir="../../models"):
        self.cache_dir = os.path.abspath(cache_dir)
        self.log_file = os.path.join(self.cache_dir, "download_log.json")
        self.download_log = self.load_log()
        os.makedirs(self.cache_dir, exist_ok=True)
        
    def load_log(self):
        """ë‹¤ìš´ë¡œë“œ ë¡œê·¸ ë¡œë“œ"""
        if os.path.exists(self.log_file):
            try:
                with open(self.log_file, 'r') as f:
                    return json.load(f)
            except:
                pass
        return {"downloads": {}, "metadata": {"created": datetime.now().isoformat()}}
    
    def save_log(self):
        """ë¡œê·¸ ì €ì¥"""
        self.download_log["metadata"]["last_updated"] = datetime.now().isoformat()
        with open(self.log_file, 'w') as f:
            json.dump(self.download_log, f, indent=2)
    
    def check_disk_space(self, required_gb=50):
        """ë””ìŠ¤í¬ ê³µê°„ í™•ì¸"""
        free_space = shutil.disk_usage(self.cache_dir).free / (1024**3)
        return free_space, free_space > required_gb
    
    def estimate_total_size(self, category_name):
        """ì¹´í…Œê³ ë¦¬ë³„ ì´ í¬ê¸° ì¶”ì •"""
        if category_name not in ESSENTIAL_MODELS:
            return 0
            
        size_map = {
            "117M": 0.5, "1.5B": 6, "3.8B": 15, "6B": 24, "7B": 28,
            "9B": 36, "10.7B": 42, "12B": 48, "12.8B": 51, "14B": 56,
            "27B": 108, "32B": 128, "70B": 280, "72B": 288
        }
        
        total_gb = 0
        for model_name, size, desc in ESSENTIAL_MODELS[category_name]["models"]:
            total_gb += size_map.get(size, 20)  # ê¸°ë³¸ê°’ 20GB
        return total_gb
    
    def download_model(self, model_name, size, description):
        """ê°œë³„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        print(f"\n{'='*60}")
        print(f"ğŸ“¥ Downloading: {model_name}")
        print(f"ğŸ“Š Size: {size} | ğŸ“ {description}")
        print(f"{'='*60}")
        
        # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ê²½ìš°
        if model_name in self.download_log["downloads"]:
            status = self.download_log["downloads"][model_name].get("status")
            if status == "success":
                print(f"âœ… Already downloaded: {model_name}")
                return True
        
        try:
            start_time = time.time()
            
            # HuggingFace Hubë¡œ ë‹¤ìš´ë¡œë“œ
            local_path = snapshot_download(
                repo_id=model_name,
                cache_dir=self.cache_dir,
                local_files_only=False,
                resume_download=True,
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            # ë¡œê·¸ ì—…ë°ì´íŠ¸
            self.download_log["downloads"][model_name] = {
                "status": "success",
                "download_time": datetime.now().isoformat(),
                "duration_seconds": round(duration, 1),
                "size": size,
                "description": description,
                "local_path": local_path
            }
            
            print(f"âœ… Success: {model_name}")
            print(f"â±ï¸  Download time: {duration:.1f}s")
            print(f"ğŸ“ Path: {local_path}")
            
            self.save_log()
            return True
            
        except Exception as e:
            print(f"âŒ Error downloading {model_name}: {e}")
            
            self.download_log["downloads"][model_name] = {
                "status": "failed",
                "error": str(e),
                "download_time": datetime.now().isoformat()
            }
            self.save_log()
            return False
    
    def download_category(self, category_name, ask_confirmation=True):
        """ì¹´í…Œê³ ë¦¬ë³„ ë‹¤ìš´ë¡œë“œ"""
        if category_name not in ESSENTIAL_MODELS:
            print(f"âŒ Unknown category: {category_name}")
            print(f"Available: {list(ESSENTIAL_MODELS.keys())}")
            return
        
        category = ESSENTIAL_MODELS[category_name]
        models = category["models"]
        
        print(f"\nğŸ¯ Category: {category_name}")
        print(f"ğŸ“‹ Description: {category['description']}")
        print(f"ğŸ“Š Models: {len(models)}")
        
        # í¬ê¸° ì¶”ì •
        total_size = self.estimate_total_size(category_name)
        print(f"ğŸ’¾ Estimated size: {total_size:.1f} GB")
        
        # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
        free_space, has_space = self.check_disk_space(total_size)
        print(f"ğŸ’¿ Available space: {free_space:.1f} GB")
        
        if not has_space:
            print(f"âš ï¸  Warning: Insufficient disk space!")
            
        # ëª¨ë¸ ëª©ë¡ í‘œì‹œ
        print(f"\nğŸ“‹ Models to download:")
        for i, (model_name, size, desc) in enumerate(models, 1):
            status = "âœ…" if model_name in self.download_log["downloads"] else "â³"
            print(f"   {i}. {status} {model_name} ({size}) - {desc}")
        
        # í™•ì¸
        if ask_confirmation:
            response = input(f"\nğŸš€ Start download? (y/N): ")
            if response.lower() != 'y':
                print("âŒ Download cancelled")
                return
        
        # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        print(f"\nğŸš€ Starting downloads...")
        success_count = 0
        
        for i, (model_name, size, desc) in enumerate(models, 1):
            print(f"\nğŸ“¦ [{i}/{len(models)}] Processing...")
            if self.download_model(model_name, size, desc):
                success_count += 1
            
            # ê°„ë‹¨í•œ ëŒ€ê¸°
            time.sleep(1)
        
        print(f"\nğŸ‰ Category '{category_name}' download complete!")
        print(f"âœ… Success: {success_count}/{len(models)} models")
        
    def show_categories(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ í‘œì‹œ"""
        print("\nğŸ“‹ Available Categories (Priority Order):")
        print("=" * 60)
        
        # ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
        sorted_categories = sorted(
            ESSENTIAL_MODELS.items(), 
            key=lambda x: x[1]["priority"]
        )
        
        for name, info in sorted_categories:
            size = self.estimate_total_size(name)
            model_count = len(info["models"])
            priority = info["priority"]
            
            print(f"\nğŸ·ï¸  {name} (Priority: {priority})")
            print(f"   ğŸ“ {info['description']}")
            print(f"   ğŸ“Š Models: {model_count}")
            print(f"   ğŸ’¾ Est. Size: {size:.1f} GB")
    
    def show_status(self):
        """ë‹¤ìš´ë¡œë“œ ìƒíƒœ í‘œì‹œ"""
        downloads = self.download_log["downloads"]
        
        if not downloads:
            print("ğŸ“­ No downloads yet")
            return
        
        print(f"\nğŸ“Š Download Status ({len(downloads)} models)")
        print("=" * 60)
        
        success_count = sum(1 for d in downloads.values() if d.get("status") == "success")
        failed_count = len(downloads) - success_count
        
        print(f"âœ… Successful: {success_count}")
        print(f"âŒ Failed: {failed_count}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìƒíƒœ
        for category_name, category_info in ESSENTIAL_MODELS.items():
            models_in_category = [m[0] for m in category_info["models"]]
            downloaded = [m for m in models_in_category if m in downloads and downloads[m].get("status") == "success"]
            
            print(f"\nğŸ“‚ {category_name}: {len(downloaded)}/{len(models_in_category)}")
            for model in models_in_category:
                if model in downloads:
                    status = "âœ…" if downloads[model].get("status") == "success" else "âŒ"
                    print(f"   {status} {model}")
                else:
                    print(f"   â³ {model}")

def main():
    parser = argparse.ArgumentParser(description="H100 Essential Model Downloader")
    parser.add_argument("--category", type=str, help="Download specific category")
    parser.add_argument("--list", action="store_true", help="List available categories")
    parser.add_argument("--status", action="store_true", help="Show download status")
    parser.add_argument("--all", action="store_true", help="Download all categories")
    parser.add_argument("--cache-dir", type=str, default="../../models", help="Cache directory")
    parser.add_argument("--yes", action="store_true", help="Skip confirmation")
    
    args = parser.parse_args()
    
    downloader = H100ModelDownloader(cache_dir=args.cache_dir)
    
    if args.list:
        downloader.show_categories()
    elif args.status:
        downloader.show_status()
    elif args.all:
        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ë‹¤ìš´ë¡œë“œ
        categories = sorted(ESSENTIAL_MODELS.keys(), 
                          key=lambda x: ESSENTIAL_MODELS[x]["priority"])
        for category in categories:
            downloader.download_category(category, not args.yes)
    elif args.category:
        downloader.download_category(args.category, not args.yes)
    else:
        print("ğŸš€ H100 Essential Model Downloader")
        print("=" * 50)
        print("\nUsage examples:")
        print("  python download_models.py --list")
        print("  python download_models.py --category size_comparison")
        print("  python download_models.py --category reasoning_models --yes")
        print("  python download_models.py --all")
        print("  python download_models.py --status")
        print("\nRecommended order:")
        print("  1. size_comparison (M3 ë¹„êµìš©)")
        print("  2. reasoning_models (ìµœì‹  ì¶”ë¡ )")
        print("  3. korean_models (í•œêµ­ì–´ íŠ¹í™”)")
        print("  4. benchmark_leaders (ì„±ëŠ¥ ë¦¬ë”)")

if __name__ == "__main__":
    # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
    try:
        from huggingface_hub import snapshot_download
    except ImportError:
        print("ğŸ“¦ Installing huggingface_hub...")
        os.system("pip install huggingface_hub")
    
    main()